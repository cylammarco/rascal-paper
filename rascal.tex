%                                                                 aa.dem
% AA vers. 9.1, LaTeX class for Astronomy & Astrophysics
% demonstration file
%                                                       (c) EDP Sciences
%-----------------------------------------------------------------------
%
%\documentclass[referee]{aa} % for a referee version
%\documentclass[onecolumn]{aa} % for a paper on 1 column  
%\documentclass[longauth]{aa} % for the long lists of affiliations 
%\documentclass[letter]{aa} % for the letters 
%\documentclass[bibyear]{aa} % if the references are not structured 
%                              according to the author-year natbib style

%
\documentclass{aa}  

%
\usepackage{graphicx}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{txfonts}
\usepackage{pdflscape}
\usepackage{xcolor}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage[options]{hyperref}
% To add links in your PDF file, use the package "hyperref"
% with options according to your LaTeX or PDFLaTeX drivers.
%
\begin{document} 

   \title{Ransac Assisted Spectral CALibration~(RASCAL)}

   \subtitle{Towards automated spectral wavelength calibration}

   \author{J. Veitch-Michaelis
          \inst{1, 3}\fnmsep\thanks{veitchjo@uwisc.edu}
          \and
          M. C. Lam\inst{2, 3}
          }

   \institute{Department of Physics and Wisconsin IceCube Particle Astrophysics Center,
University of Wisconsin, Madison, WI 53706, USA
         \and
        School of Physics and Astronomy, Tel Aviv University, Tel Aviv 69978, Israel
         \and
        Astrophysics Research Institute, Liverpool John Moores University, IC2, LSP, 146 Brownlow Hill, Liverpool L3 5RF, UK
             }

   \date{Received \today}

% \abstract{}{}{}{}{} 
% 5 {} token are mandatory
 
  \abstract
  % context heading (optional)
  % {} leave it empty if necessary  
   {Wavelength calibration is a routine and critical part of any spectral work-flow, but many astronomers still resort to matching detected peaks and emission lines by hand. \textcolor{red}{More stuff here.}}
  % aims heading (mandatory)
   {We present \texttt{RASCAL} (RANSAC Assisted Spectral CALibration), a \texttt{Python} library for automated wavelength calibration of astronomical spectrographs. \texttt{RASCAL} implements recent state-of-the-art methods for wavelength calibration and requires minimal input from a user. \textcolor{red}{More stuff here.}}
  % methods heading (mandatory)
   { \textcolor{red}{More stuff here.}}
  % results heading (mandatory)
   {we have developed \texttt{RASCAL} (RANSAC-Assisted Spectral CALibration), which only requires an atlas of calibration lines, a list of peaks, and some information about the system. \textcolor{red}{More stuff here.}}
  % conclusions heading (optional), leave it empty if necessary 
   { \textcolor{red}{More stuff here.}}

   \keywords{bla --
                blabla --
                blablabla
               }

   \maketitle
%
%-------------------------------------------------------------------
\section{Introduction}
Wavelength calibration is a routine and critical part of spectral data reduction
workflow. This usually involves manually matching peaks in an arc lamp spectrum to a
catalogue of known emission lines~\citep{2010MNRAS.409.1601B}. This is an extremely
repetitive process and they accumulate to take up a substantial amount of time.
Even for an experienced user, there is a bottleneck on how fast a manual reduction
can reach.

The advances in Astronomy in the past decade has enabled multi-epoch, multi-colour
large sky-area surveys. Among the ground-base facilities, to name a few, the
Optical Gravitational Lensing Experiment~\citep[OGLE]{2015AcA....65....1U},
All-Sky Automated Survey for Supernovae~\citep[ASAS-SN]{2017PASP..129j4502K},
ZTF~\citep[Zwicky Transient Facility]{2019PASP..131a8003M},
BlackGEM~\citep[BlackGEM]{2015ASPC..496..254B}
Gravitational-wave Optical Transient Observer~\citep[GOTO]{2020SPIE11445E..7GD}
Panoramic Survey Telescope and Rapid Response System~\citep[Pan-STARRS]{2016arXiv161205560C}
and forthcoming Vera Rubin Observatory~\citep[VRO]{2019ApJ...873..111I}. Both Galactic
and extra-Galactic transient events are being found in steadily growing numbers.
However while it is relatively easy to discover, for example, a supernova, it is much
harder to collect the essential follow-up observations (both photometry and spectroscopy)
to allow classification and subsequent scientific exploitation. In addition, with the
advent of multi-messenger Astronomy with Gravitational Waves with
LIGO~\citep{2015CQGra..32g4001L} and VIRGO~\citep{2015CQGra..32b4001A} and neutrino
detectors, the IceCube~\citep{2006APh....26..155I}, rapid time-domain photometric and
spectroscopic observations are becoming even more crucial to identify and confirm their
electromagnetic counterparts. Hence, The quick turnover of the full data reductions is
important in case of Target-of-Opportunity requests, which are best performed on robotic
telescopes. They can swiftly follow up short-lived events like unusual supernovae,
cataclysmic variables~(CVs), planetary deviations in microlensing events, etc. This can only be
made possible, with a global network of small/medium sized telescope dedicated for
follow-up. They, however, even when the control systems are roboticized, most of the
data curation is still relying heavily on manual operation. Despite there are various
large scale spectroscopic surveys with high volume of data output and automated data
reduction, for example, The Large Sky Area Multi-Object Fiber Spectroscopic
Telescope~\citep[LAMOST]{2012RAA....12.1197C}, WHT Enhanced Area Velocity
Explorer~\citep[WEAVE]{2012SPIE.8446E..0PD}, 4-metre Multi-Object Spectroscopic
Telescope~\citep[4MOST]{2019Msngr.175....3D}, Galactic Archaeology with
Hermes~\citep[GALAH]{2015MNRAS.449.2604D}, Radial Velocity
Experiment~\citep[RAVE]{2020AJ....160...82S}, Mapping Nearby Galaxies at Apache Point
Observatory~\citep[MaNGA]{2015ApJ...798....7B} etc. They come with dedicated data
reduction pipeline, with the software pruned to optimise performance in their specific
settings. The large number of data collected simultaneously allows cross-calibration
to certain extent. These generally unportable setups make the data reduction system
difficult to be reused. The integration effort can be just as, significant
as rewriting a new dedicated software that is specific to the newly roboticized
systems~\citep{2010SPIE.7740E..0WT}. While the most commonly, the data reduction process
is left for the individual scientists to complete, this is both inefficient in use of
highly skilled resources, causes wasted duplication of software, and can lead to
inhomogeneous data products that are difficult to combine from different facilities and
observers.

The Time Domain Astronomy section of the OPTICON recognise this series of issues and
initiated an effort to develop a portable spectrograph and a portable data reduction
software. They are now the SPRAT~\citep{2014SPIE.9147E..8HP} on the Liverpool
Telescope~\citep{2004SPIE.5489..679S} at the Observatorio Astrof{\'i}sico Roque de los
Muchachos, the MOOKODI on the Lesedi Telescope 
at the South African Astronomical Observatory, and the MISTRAL on the 1.93\,m
telescope at the Haute-Provence Observatory. On the data reduction side, a new
general spectral pipeline, \texttt{ASPIRED}~\citep{2020arXiv201203505L, 2020zndo...4306065L},
that is completely independent of \texttt{iraf}~\citep{1986SPIE..627..733T} is under
active development and it is close to completion. It has been a concurrent development
of the \texttt{RASCAL} software~(this work) that handles the wavelength
calibration~\citep{2019arXiv191205883V, 2020zndo...4117517V}.

This following article is organised in this structure: in Section~2, we will address
the difficulties in achieving automated wavelength calibration; in Section~3,
\texttt{RASCAL} will describes in detail; the quality and the repeatability will
be demonstrated in Section~4; the deployment on various systems and some example
independent demonstrators will be reported in Section 5; in the final section, we
will conclude on the software, including the limitation, maintenance, and the potential
future development.

\section{Wavelength Calibration}
The process of wavelength calibration involves identifying distinctive emission lines
from an arc lamp spectrum, from which a polynomial can be found to map the pixel
position to the wavelength value. Automating this process may seem trivial, but in
real life application, it is not remotely easy. The strong dependency on the 
instrumental properties have made the wavelength calibration routines specific to
the instruments, to name a few, the vacuum/contamination condition of the lamp, the 
combination of elements in the lamp, the vignetting on the focal plan, the response
as function of wavelength across the detector, saturation issue. There is also likely
to be noise in the peak finding routines, for example, due to detector noise or
quantization~(e.g.\ not using sub-pixel peak finding). There may also be complications
such as blended lines - detected peaks which correspond to multiple emission lines,
tsuch as unresolved doublets. While many observatories have published reduction
pipelines that involve wavelength calibration~\citep{2002AJ....123..485S,
2012ascl.soft03003C, 2013ApJS..208....5N}, they are not transferable to other setups.
In one specific general common pipeline, \texttt{PypeIt}~\citep{2020JOSS....5.2308P},
it uses spectral template matching for wavelength calibration, and it is done specific
per instrument. As we have discussed in the previous section, there is a growing need
for an automated solution that is easily transferable and robust to system 
re-configuration e.g. grating position, lamp type. This would be particularly
useful in sharing a single data reduction pipeline among a network of small telescope
facilities when staffing for software development and maintenance is limited.
In order to address this, we have developed \texttt{RASCAL}~(RANSAC-Assisted Spectral CALibration).
\texttt{RASCAL} only requires an atlas of calibration lines, a list of peaks, and some information
about the system. \texttt{RASCAL} has been developed for the \texttt{ASPIRED}
program~\citep{2019arXiv191205885L, 2020arXiv201203505L, 2020zndo...4306065L}
and broadly follows the algorithm presented in \citet{2018ApOpt..57.6876S}. We are
releasing \texttt{RASCAL} as open-source as a \texttt{Python} library that can be easily integrated in to
astronomical pipelines. The original paper only presents results from commercial
spectrometers, so we contribute an initial evaluation on real-world spectra
from astronomical instruments. We also present some tweaks and improvements to the
original algorithm that result in improved correspondence matching.

\subsection{Challenges}
Motivated by the computer vision algorithm, \citet{2018ApOpt..57.6876S} applies an
outline detection algorithm making use of Hough transform to quickly identify first
good guess of a pixel-to-wavelength polynomial solution. The proposition for an ideal
system is: \textbf{given a set of detected peak locations in an arc spectrum ($P$ [px]),
there exists a set of matching emission lines ($A$ [$\lambda$]) for every $P$}.
Once the correspondences between $P$ and $A$ have been established, they are
used to fit a model $f(x, p) = x_{\lambda}$ where $p$ are model parameters, $x$ is a
detector location in pixels and $x_{\lambda}$ is the corresponding wavelength.
Because of the aforementioned instrumental/optical effects and imperfection in the
system, this process is not as straight forward and has to be robust against outliers.
Nevertheless, the emission lines in the atlas are assumed to be perfect and taken
from the National Institute of Standards and Technology~\citep[NIST]{NIST\_ASD}
which collates values from the literature; alternately, users can supply a line list.
No assumption is made about the peak finding routine, see next section for more details.
It is possible that some detected peaks are spurious or correspond to a line not in the
atlas. Vice versa, it is possible that some atlas lines were not detected because they
are outside the spectral range of the detector, too low in amplitude, and so on. In
fact, in the general case, the real problem we face is: \textit{for any combination of
member of $P$, there usually exists a corresponding member of $A$}. The goal is to find
the true line in $A$ for each peak in $P$. Checking all possible sets of pairs of $A$
and $P$ for each spectrum is computationally infeasible. Once peaks and wavelengths
have been matched, the model fitting process is largely traditional. It is important that
robust fitting methods are used, otherwise a single incorrect match can significantly
skew the final model parameters.

\section{RASCAL}
In \citet{2018ApOpt..57.6876S}, they search for \textit{plausible} sets of
correspondences which are constrained by prior knowledge about the system.
Specifically they find solutions which agree with linear approximations to the
system~($x_\lambda = Dx + c$). We likely know which lamp was used, and we also have
priors on the minimum wavelength~($c$) and dispersion ($D$) of the system. Let $A'$ be
a filtered atlas which only contains lines within a user-specified range of interest.
We allow a default tolerance of $\pm 200$\AA~to this value. We constrain $D$ based on
the number of pixels in the spectrum and the wavelength range.

The original algorithm suggests fitting models to each Hough candidate set separately
and then choosing the best. In our experience, this fails when there is a non-negligible
curvature in the model function. Instead, we consider the top $N$ candidate sets
simultaneously (we set $N = 20$ by default). For each peak, we choose the most common
best-fit atlas line from the top candidate sets. This acts somewhat like a piece-wise
linear fit and allows us to extract most of the correct matches from both the red and
blue regions of the spectrum. RANdom SAmple
Consensus~\citep[RANSAC][]{fischler_bolles_1981} is used to robustly fit
a higher order polynomial model to the candidate correspondences. This model is used
to return atlas correspondences for each peak, which can be passed to a more
sophisticated fitting function e.g. an analytical model of the instrument such as
in \citet{2013OptEn..52a3603L}.

Three built-in diagnostic plots are available, each is available in both
\texttt{plotly}~\citep{plotly} and \texttt{matplotlib}~\citep{Hunter:2007, thomas_a_caswell_2021_4743323}. The former can generate interactive plots
readable by a browser, while being able to be rendered as static plots. However,
the installation can be difficult at times, so it is not our default plotting
library. In fact, it is not even installed as a dependency. On the other hand,
\texttt{matplotlib} is the most commonly used plotting library
among \texttt{Python} users, it has no known problematic upstream dependency issue.
Therefore, it is chosen as our default plotting library. Its lack of
interactivity has a small drawback, but there are external packages that can
convert a \texttt{matplotlib} figure object into interactive plots, for example
with \texttt{mpld3}\footnote{\url{http://mpld3.github.io/}}, and this can be done
completely outside the functional call of \texttt{RASCAL}.

\subsection{Hough Transform}
Initially, every pair of peaks and emission lines are enumerated~(i.e.\ the
Cartesian product of the sets $A' \times P$.) The Hough
transform~\citep{osti_4746348} is used to search for linear correspondences
among these enumerated pairs. The result of this is a histogram of possible lines
in $(D, c)$ space. Peaks in the Hough space corresponds to straight lines
in the pixel-wavelength space which pass through (or near) many sets of
$A' \times P$; we call this a candidate pair/set hereafter.

\subsection{RANSAC}
Random sample consensus, RANSAC, is an algorithm for robust fitting,
popularized by the computer vision community~\citep{fischler_bolles_1981}.

Suppose we have a dataset that contains good points~(inliers) and spurious
points~(outliers). If we randomly sample our dataset, eventually we will
pick a set of points which only contain the inliers. In that case, a model
fit to this sample should also fit the majority of the rest of our data.
Conversely if we sample an outlier by mistake, the fit will not agree with
the rest of the dataset.

This is conceptually very simple, but works extremely well in practice.
Typically the sample size is the minimum required to fit the model, so for
a linear model we would draw 2 random points. If you know the percentage of
outliers in your data it is possible to calculate some statistical estimate
of how many iterations is required before an inlier-only sample is drawn~(to
some degree of confidence). In practice, we never know the inlier-to-outlier
ratio so we need to try ``a large number'' of samples\footnote{From experience,
a few hundred is ``a lot''}. This number of samples can also be adjusted as 
a hyperparameter for the algorithm to provide best results on a specific
instrument. We need to emphasise that using the default line list without any
pruning by users will lead to slow computation and low repeatability.

We also need to decide how to score a particular sample fit. In the original
version of RANSAC, the number if inliers corresponding to a fit is used. More
inliers equals a better fit. In \texttt{RASCAL} we use a slight modification called
M-SAC~\citep{Torr00mlesac:a} which also weights inliers by the fit error.
This is useful because it acts as a tie-breaker between two fits with the
same number of inliers.

\subsection{Procedure}
In the following article, we refer a spectrum of an arc as an \textit{arc},
the wavelength of the emission lines from an arc as \textit{lines}, whereas 
the \textit{peaks} are the pixel position where the lines are centred at,
and a collection of lines from some elements as \textit{atlas}.

The following is \textbf{not} served as an API document, we are only highlighting
the important and special features and limitations.

\subsubsection*{Step 1 -- Initialise a Calibrator}
A calibrator can be initialized with \texttt{Calibrator(peaks)} by passing a list
of pixel values of the the peaks identified from an arc frame. This also
initialises a logger inside to handle five levels of messages -- \texttt{debug},
\texttt{info}, \texttt{warning}, \texttt{error} and \texttt{critical}, and a
Hough transform instance with \texttt{HoughTransform()} that handles the
transformation and the operations in Hough space. The properties of the
calibrator, Hough transform and the RANSAC are set with their own functions to
avoid confusion of similar name space, particularly regarding the limits and
tolerances, namely:

\subsubsection*{i. \texttt{set\_calibrator\_properties()}}
The two main parameters to set are the \texttt{num\_pix} and \texttt{pixel\_list}.
The latter can be ignored in most cases when the wavelength calibration is performed
on a single detector. This is also where to choose the plotting library between
\texttt{matplotlib} or \texttt{plotly}; and the verbosity level of the logger.

\subsubsection*{ii. \texttt{set\_hough\_properties()}}
This function controls the Hough transform. It defines the binning parameters for
generating the Hough pairs, the wavelength ranges of the atlas, and the tolerances
in which Hough pairs will be accepted~(see Fig~\ref{fig:threshold}).

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{plots/figure_1_threshold_plot.png}
    \caption{This illustrate how the \texttt{linearity\_thresh},
    \texttt{range\_tolerance} and the wavelength limits restrict the parameter
    space in the Hough space to significantly reduce the possible solution Hough
    pairs.}
    \label{fig:threshold}
\end{figure}

\subsubsection*{iii. \texttt{set\_ransac\_properties()}}
After supplying the atlas, we also need to define the properties of the RANSAC
operations. It needs the knowledge of both the atlas and the set of Hough pairs
so it cannot be predefined unless it is already deployed in some routine or
automated processing that the fitting parameters are already well known to
achieve desired output quality. The closely spaced Hough candidates can be
removed by setting \texttt{filter\_close} to \texttt{True}, where the peaks with
higher intensity among the closely spaced lines will be kept.

\subsubsection*{Step 2 -- Supply atlas}
An atlas can be loaded from the built-in list of cleaned NIST list with
\texttt{load\_atlas()}, the intensity of the lines are also included.
However, there is no easy way to account for the response function of
the detector without field-flattening and flux calibration, which in turn
requires wavelength calibration. The intensity setting should only be
used for removing faint lines. It is also possible to, and in fact
recommended, for users to provide a user-defined set of atlas with the
function \texttt{add\_user\_atlas()}. This can significantly improve
both the quality of fit as well as the speed of the fitting process.

\subsubsection*{Step 3 -- Configure the operations in Hough space}
The set of Hough pairs are generated with \texttt{set\_peaks()} which uses
\texttt{\_generate\_pairs()} to
\begin{enumerate}
    \item Pair up \texttt{peaks} (piexls) and \texttt{atlas} (wavelength)
    \item If \texttt{constrain\_poly} is set to \texttt{True},
        \texttt{Delaunay} from \texttt{scipy} is usd to remove outlying points.
    \item Order the pairs into a sorted list of [(peak 1, atlas 1),
        (peak 2, atlas 2), ..., (peak n, atlas n)]
    \item Optionally, append the known (peak, atlas) pairs with
        \texttt{set\_known\_pairs()} which are used as anchor(s) when solving
            for the solutions. This function has to be used with extreme
            caution, a set of wrong \textbf{known pairs} will guarantee
            poor or failed fit.
\end{enumerate}

\subsubsection*{Step 4 -- Run Hough Transform}
When executing the \texttt{\_do\_hough\_transform()}, the Hough parameters
will be propagated to the HoughTransform instance immediately before
executing the \texttt{generate\_hough\_points()} and
\texttt{bin\_hough\_points()} to generate the set of 
(1)~\texttt{hough\_points}, and (2)~\texttt{hough\_lines}. A HoughTransform
instance can be saved and loaded as \texttt{npy} or plain text \texttt{json}
files.

\subsubsection*{Step 5 -- Fit for the solution}
Most of the parameters were already set in with the three functions described
in step 1. At this point, only the fitting parameters are remained to be
configured: the number of iterations -- \texttt{max\_tries}, the degree of
polynomial to be fitted (\texttt{fit\_deg}), a starting set of polynomial
coefficients~(\texttt{fit\_coeff}), the acceptance threshold~
(\texttt{fit\_tolerance}) and the type of polynomial which can be chosen
from \texttt{ploy} for basic polynomial function, \texttt{legendre} or Legendre
polynomial function and \texttt{chebyshev} Chebyshev polynomial function. The
\texttt{brute\_force} can be set to True to discard the \texttt{max\_tries}
and try all possible combination in the given parameter space. The
\texttt{progress} is set to True by default to use the \texttt{tqdm} package
to show the progress of the fit.

The \texttt{fit()} function handles the heavy duty using the
\texttt{\_solve\_candidate\_ransac()}. It starts from getting the possible
wavelength solution of all the peaks for the given \texttt{hough\_line}, which
generates the \texttt{candidates} that contain the (1)~Hough solution wavelength,
(2)~atlas wavelength, and (3)~weight of the solution. The most common weighted
candidates will then be chosen with the \texttt{\_get\_most\_common\_candidates()}
by counting and returning the \texttt{top\_n} most common Hough solution wavelength.
The fit will stop and return nothing if the number of candidates is smaller than
the (degree of the polynomial + 1). From the Hough pairs, an interpolated 2D
density map is built in the Hough space, which is used as a weight map,
\texttt{weight}, in the fitting process. The pixel-wavelength solution will be
solved with the chosen polynomial function. The fit will be discarded if the two
lowest polynomials co-efficients are outside the combined tolerance limits. The
absolute difference between the solutions and the atlas will give us the
uncertainties, \texttt{err}, of the solution. The \texttt{cost} function can
be computed by combining the \texttt{err} and \texttt{weight}. If the new cost
is lower, the new solution will be accepted.

An optional function \texttt{match\_peaks} is also available to refine the
fitted solution. It comes in two modes, the first is a more stable and
conservative way to refit the solution by searching for the wavelength-calibrated
peaks that are within the given tolerance limit from the atlas supplied. This
can give a marginally better fit, particularly reducing the root-mean-squared
measured. The second mode can be enabled by setting \texttt{refine} to
\texttt{True}, in this case, the small perturbation will be added to the accepted
set of polynomial coefficients and then a minimisation routine will be used to
fit for the new polynomial.

\subsubsection*{Diagnostics}
\texttt{RARCAL} comes with three built-in diagnostic plots, the most basic
one is the \texttt{plot\_arc} function which plot the arc spectrum
supplied along with the detected peaks. The other two are far more useful:
the \texttt{plot\_search\_space()} shows the search area in Hough space and
the final sets of Hough lines that were used in the solution; the
\texttt{plot\_fit()} displays the wavelength calibrated arc spectrum, the
residual of the solution as a function of wavelength, and the fitted polynomial
function as a function of wavelength.

\section{Quality and Repeatabality}

\subsection{Testing framework with simulated spectra}

One of the goals of \texttt{RASCAL} is to be agnostic to the choice of calibration
lamp or target. With  this in mind, it is not necessary to simulate a specific
lamp for testing.


\subsection{Testing with LT/SPRAT Xe lamp}

In order to compare the quality of wavelength calibration, the repeatability and
convergence rates when using automatic line list vs manual line list, we repeat the
wavelength calibration of an arc taken with the LT/SPRAT Xe lamp 1000 times at a
maximum number of trials at 25, 50, 100, 150, 200, 250, 500, 1000, 2000, and 5000.
Both the automatic and manual line lists are only referring to a set of wavelengths
of the template arc lines. The set of peaks used in both cases are identical, which
were determined automatically.

In figure~\ref{fig:coefficients}, we show the distributions of the five polynomial
coefficients in each of the cases for comparison. The better the repeatability, the
smaller the distribution is (a large kurtosis). It is clear that there is a correlation
between the size of the \texttt{max\_tries} and the kurtosis of the distributions. And
the manual line list is showing a more rapid convergence as it has a faster rate of
growth in the kurtosis, although, the two modes do not usually reach the same maximum
kurtosis as a manual line list is pruned to guarantee a unique set of solution given a
sufficiently large \texttt{max\_tries} while the auto line lists may give best fit
solutions coming from different local minima depending on the initial conditions of
the finite sampling.

The root-mean-squares of the residual from the $1000 \times 11$ fits are shown in the
violin plots in Fig.~\ref{fig:rms}. The quality of fit does not increase with the size
of \texttt{max\_tries}, but the distributions become smaller. This means the
repeatability is higher at larger \texttt{max\_tries}. This is not surprising, given
it is unreliable and in fact a bad practice to rely on a single quantity to determine
the quality of fit. In the auto line list mode, the spread as a function of
\texttt{max\_tries} is consistently larger than in manual mode due to multiple local
minima coming from fitting spurious lines.

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{plots/figure_2_rms.png}
    \caption{The distribution of the 1000 RMS values at the 8 \texttt{max\_tries} for auto line list (top) and manual line list (bottom). The convergence rate is much faster and the solution is much more stable when a known line list is provided.}
    \label{fig:rms}
\end{figure}


\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{plots/figure_4_peak_utilisation.png}
    \caption{The distribution of the 1000 \texttt{peak\_utilisation} values at the 8 \texttt{max\_tries} for auto line list (top) and manual line list (bottom). The low utilisation fraction in the top figure indicates that the auto line list contains much more lines than the number of peaks being detected. The near-perfect utilisation fraction in the manual list demonstrates that \texttt{rascal} has a high repeatibility despite the trial samples are drawn completely randomly in the first place.}
    \label{fig:peak_utilisation}
\end{figure}


\begin{figure*}[h]
    \centering
    \includegraphics[width=\textwidth]{plots/figure_5_wavelengths.png}
    \caption{From left to right, they show the distributions of the wavelength solution at pixel 150, 350, 550, 750 and 950 at the 8 \texttt{max\_tries} with automatic line list (top), and manual line list (bottom). The smallest and largest pixel positions are at the two ends of the usable spectral wavelength range. The grid spacing in each column is identical but they vary across the columns: each spacing in the x-axis corresponds to the resolution~($\Delta\lambda$) at that wavelength. There is a clear pattern of a narrower distribution with larger \texttt{max\_tries}. It is also clear that manual line list outperforms auto line list significantly. The statistics can be referred to Table~\ref{tab:stats}.}
    \label{fig:wavelengths}
\end{figure*}

The repeatibility is illustrated in a different way in Fig.~\ref{fig:heatmap} by
plotting the heatmaps of the deviations from the true fit as a function of pixel
across the detector. For perfect fitting every time, it should give a delta function
at $\Delta \lambda = 0$ at all pixels, which would appear as a bright horizontal line.
In the case of auto line list, there are notably more deviated fits compared to
that using a manual line list. 

\begin{figure}[h]
    \centering
    \includegraphics[width=\columnwidth]{plots/figure_6_heatmap.png}
    \caption{The heatmaps showing the deviation of the fitted wavelengths from the true value as a function of pixel. The using auto line list (top) is giving good solutions most of the time, but it is clear that the manual line list completely outperforms the automatic one.}
    \label{fig:heatmap}
\end{figure}

\begin{table*}
    \centering
    \begin{tabular}{c|c|ccccc|c|ccccc}

        Grating & \texttt{max\_tries} & c0 & c1 & c2 & c3 & c4 & RMS & $\Delta\lambda_{150}$ & $\Delta\lambda_{350}$ & $\Delta\lambda_{550}$ & $\Delta\lambda_{750}$ & $\Delta\lambda_{950}$\\
        \hline
        \hline
          & 100 & d & d & d & d & d & d & d & d & d & d & d \\
          & 150 & d & d & d & d & d & d & d & d & d & d & d \\
          & 200 & d & d & d & d & d & d & d & d & d & d & d \\
        LT/SPRAT & 250 & d & d & d & d & d & d & d & d & d & d & d \\
        (auto) & 500 & d & d & d & d & d & d & d & d & d & d & d \\
          & 1000 & d & d & d & d & d & d & d & d & d & d & d \\
          & 2000 & d & d & d & d & d & d & d & d & d & d & d \\
          & 5000 & d & d & d & d & d & d & d & d & d & d & d \\\hline
          & 100 & d & d & d & d & d & d & d & d & d & d & d \\
          & 150 & d & d & d & d & d & d & d & d & d & d & d \\
          & 200 & d & d & d & d & d & d & d & d & d & d & d \\
        LT/SPRAT & 250 & d & d & d & d & d & d & d & d & d & d & d \\
        (manual) & 500 & d & d & d & d & d & d & d & d & d & d & d \\
          & 1000 & d & d & d & d & d & d & d & d & d & d & d \\
          & 2000 & d & d & d & d & d & d & d & d & d & d & d \\
          & 5000 & d & d & d & d & d & d & d & d & d & d & d \\\hline
    \end{tabular}
    \caption{Caption}
    \label{tab:stats}
\end{table*}


\section{Distribution}
The \textsc{RASCAL} is released under the BSD (3-Clause) License. The
source code is hosted on \textsc{Github}, which can be found at
\verb+https://github.com/jveitchmichaelis/rascal+, the tagged copied together
with the DOI of each version can be found at
\textsc{zenodo} \verb+https://zenodo.org/record/4117517#.YQfq2I4zYrQ+.
For simpler installation process, they are also available at Python
Package Index~(PyPI): \verb+https://pypi.org/project/rascal/+ such that
users can install the software by a simple command of 
\begin{verbatim}
    pip install rascal.
\end{verbatim}
While the development version can be installed with
\begin{verbatim}
pip install git+https://github.com/
    jveitchmichaelis/rascal@dev
\end{verbatim}

A rich resource of examples is available at
\verb+https://github.com/jveitchmichaelis/rascal-example+
where \verb+Jupyter+ notebooks are available to demonstrate the wavelength
calibration of the following long-slit instruments: (1)~NTT/EFOSC/Grism11,
(2)~Gemini GMOS longslit mode, (3)~GTC/OSIRIS/R1000B, (4)~KECK/DEIMOS/830G,
(5)~LT/SPRAT/Red, and (6)~WHT/ISIS/R300R. The examples cover elements
He, Ne, Ar, Cu, Kr, Xe, and Hg.

%--------------------------------------------------------------------
\section{Conclusions}

\textcolor{red}{More stuff here.}

Auto line list should be used to assist the preliminary line list selection
but not used at production level due to the relatively low repeatibility.
It can narrow down a subset of lines that can be adopted for full
automation with high reliability once quality check is performed by human.


%--------------------------------------------------------------------
\begin{acknowledgements}

    \textcolor{red}{Steve's astroecology money}\\
    
    \textcolor{red}{Josh's ICECUBE money}\\

    This work was partially supported by OPTICON. This project has
    received funding from the European Union’s Horizon 2020 research and
    innovation programme under grant agreement No 730890. This material
    reflects only the authors views and the Commission is not liable for
    any use that may be made of the information contained therein.\\
    
    This work was partially supported by the Polish NCN grant Daina
    No. 2017/27/L/ST9/03221.\\
    
    \textcolor{red}{Iair's ERC}\\
    
    The LT is operated on the island of La Palma by Liverpool
    John Moores University in the Spanish Observatorio del Roque
    de los Muchachos of the Instituto de Astrof{\'i}sica de Canarias with
    financial support from the UK Science and Technology Facilities
    Council.
\end{acknowledgements}

% WARNING
%-------------------------------------------------------------------
% Please note that we have included the references to the file aa.dem in
% order to compile it, but we ask you to:
%
% - use BibTeX with the regular commands:
%   \bibliographystyle{aa} % style aa.bst
%   \bibliography{Yourfile} % your references Yourfile.bib
%
% - join the .bib files when you upload your source files
%-------------------------------------------------------------------

\bibliographystyle{aa}
\bibliography{rascal}

\end{document}
